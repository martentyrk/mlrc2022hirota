Notes FACT

- two classifiers are trained to measure LICD and LICM, can we really say that the difference is due to bias, or is it more that the classifier gives different result because of the training data?
- Why not combine the two datasets and train one classifier on that, then calculate the LICD and LICM by testing on human annotated and generated caption respectively.
- How is language encoder used ? Where? and how?


- https://towardsdatascience.com/interpreting-the-prediction-of-bert-model-for-text-classification-5ab09f8ef074
- Above link is integrated gradients, using Captum library for pytorch. This works for all pytorch models, and is a way to show importance of each individual feature to the prediction.


--PROGRESS Attention explainability:
	-TODO: verify CAPTUM results, currently (18/01) it seems wrong.
	- question: Why do the authors use last_hidden_state[:,0,:] instead of _, cls_token = lang_model(args)? What is the purpose of this step? (model.py) (OLD)


--ANALAYSIS
	-23/01: Changed the dataset of human caption and model generated caption to be overlapping 100%. Originally the paper does the two pickle files on img_id so the balanced dataset added different entries for human vs model generated captions. Now we sort the prediction files first so that both datasets are overlapping. 
	This is a pretty big change in the original code and we use this only for analysis, but is it necessary to report this? What about the results we got earlier. 
	We checked for nic equalizer on bert finetuned and the results were within the original results.